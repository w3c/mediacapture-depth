<!DOCTYPE html>
<html>
  <head>
    <title>
      Media Capture Depth Stream Extensions
    </title>
    <meta charset="utf-8">
    <script src="https://www.w3.org/Tools/respec/respec-w3c-common" class=
    "remove">
</script>
    <script class="remove">

      var respecConfig = {
        specStatus: "ED",
        shortName: "mediacapture-depth",
        previousPublishDate: "2015-12-08",
        previousMaturity: "WD",
        edDraftURI: "https://w3c.github.io/mediacapture-depth/",
        editors: [
            {
              w3cid:      "41974",
              name:       "Anssi Kostiainen",
              company:    "Intel",
              companyURL: "http://www.intel.com/"
            },
            {
              w3cid:      "68202",
              name:       "Ningxin Hu",
              company:    "Intel",
              companyURL: "http://www.intel.com/"
            },
            {
              w3cid:      "76096",
              name:       "Rob Manson",
              company:    "Invited Expert"
            }
        ],
        wg: [
          "Device and Sensors Working Group",
          "Web Real-Time Communications Working Group"
        ],
        wgURI: [
          "https://www.w3.org/2009/dap/",
          "https://www.w3.org/2011/04/webrtc/"
        ],
        wgPublicList: "public-media-capture",
        wgPatentURI: [
          "https://www.w3.org/2004/01/pp-impl/47318/status",
          "https://www.w3.org/2004/01/pp-impl/43696/status"
        ],
        otherLinks: [{
        key: "Participate",
        data: [
          {
            value: "public-media-capture@w3.org",
            href: "https://lists.w3.org/Archives/Public/public-media-capture/"
          },
          {
            value: "GitHub w3c/mediacapture-depth",
            href: "https://github.com/w3c/mediacapture-depth/"
          },
          {
            value: "GitHub w3c/mediacapture-depth/issues",
            href: "https://github.com/w3c/mediacapture-depth/issues"
          },
          {
            value: "GitHub w3c/mediacapture-depth/commits",
            href: "https://github.com/w3c/mediacapture-depth/commits/"
          }
        ]
        }],
        localBiblio: {
          "MEDIACAPTURE-WORKER": {
              title:     "Media Capture Stream with Worker",
              href:      "https://w3c.github.io/mediacapture-worker/",
              authors:  [
                         "Chia-hung Tai",
                         "Robert O'Callahan",
                         "Tzuhao Kuo",
                         "Anssi Kostiainen"
              ],
              status:    "ED",
              publisher: "W3C"
          }
        }
    };

    </script>
    <script src=
    "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_CHTML">
</script>
  </head>
  <body>
    <section id="abstract">
      <p>
        This specification <a href=
        "https://w3c.github.io/mediacapture-main/#extensibility">extends</a>
        the <em>Media Capture and Streams</em> specification [[!GETUSERMEDIA]]
        to allow a <a>depth-only stream</a> or combined <a>depth+color
        stream</a> to be requested from the web platform using APIs familiar to
        web authors.
      </p>
    </section>
    <section id="sotd">
      <p>
        This extensions specification defines a new media type and
        constrainable property per <a href=
        "https://w3c.github.io/mediacapture-main/#extensibility">Extensibility</a>
        guidelines of the <em>Media Capture and Streams</em> specification
        [[!GETUSERMEDIA]]. Horizontal reviews and feedback from early
        implementations of this specification are encouraged.
      </p>
    </section>
    <section>
      <h2>
        Introduction
      </h2>
      <p>
        Depth cameras are increasingly being integrated into devices such as
        phones, tablets, and laptops. Depth cameras provide a <a>depth map</a>,
        which conveys the distance information between points on an object's
        surface and the camera. With depth information, web content and
        applications can be enhanced by, for example, the use of hand gestures
        as an input mechanism, or by creating 3D models of real-world objects
        that can interact and integrate with the web platform. Concrete
        applications of this technology include more immersive gaming
        experiences, more accessible 3D video conferences, and augmented
        reality, to name a few.
      </p>
      <p>
        To bring depth capability to the web platform, this specification
        <a href=
        "https://w3c.github.io/mediacapture-main/#extensibility">extends</a>
        the <code><a>MediaStream</a></code> interface [[!GETUSERMEDIA]] to
        enable it to also contain depth-based
        <a><code>MediaStreamTrack</code></a>s. A depth-based
        <a><code>MediaStreamTrack</code></a>, referred to as a <a>depth stream
        track</a>, represents an abstraction of a stream of frames that can
        each be converted to objects which contain an array of pixel data,
        where each pixel represents the distance between the camera and the
        objects in the scene for that point in the array. A
        <code><a>MediaStream</a></code> object that contains one or more
        <a>depth stream track</a>s is referred to as a <a>depth-only stream</a>
        or <a>depth+color stream</a>.
      </p>
      <p>
        Depth cameras usually produce 16-bit depth values per pixel, so this
        specification defines a 16-bit grayscale representation of a <a>depth
        map</a>.
      </p>
    </section>
    <section>
      <h2>
        Use cases and requirements
      </h2>
      <p>
        This specification attempts to address the <a href=
        "https://www.w3.org/wiki/Media_Capture_Depth_Stream_Extension">Use
        Cases and Requirements</a> for accessing depth stream from a depth
        camera. See also the <a href=
        "https://www.w3.org/wiki/Media_Capture_Depth_Stream_Extension#Examples">
        Examples</a> section for concrete usage examples.
      </p>
    </section>
    <section id="conformance">
      <p>
        This specification defines conformance criteria that apply to a single
        product: the <dfn>user agent</dfn> that implements the interfaces that
        it contains.
      </p>
      <p>
        Implementations that use ECMAScript to implement the APIs defined in
        this specification must implement them in a manner consistent with the
        ECMAScript Bindings defined in the Web IDL specification [[!WEBIDL]],
        as this specification uses that specification and terminology.
      </p>
    </section>
    <section>
      <h2>
        Dependencies
      </h2>
      <p>
        The <code><a href=
        "https://w3c.github.io/mediacapture-main/archives/20160513/getusermedia.html#idl-def-MediaStreamTrack">
        <dfn>MediaStreamTrack</dfn></a></code> and <code><a href=
        "https://w3c.github.io/mediacapture-main/archives/20160513/getusermedia.html#idl-def-MediaStream">
        <dfn>MediaStream</dfn></a></code> interfaces this specification extends
        are defined in [[!GETUSERMEDIA]].
      </p>
      <p>
        The <code><a href=
        "https://w3c.github.io/mediacapture-main/archives/20160513/getusermedia.html#idl-def-Constraints">
        <dfn>Constraints</dfn></a></code>, <code><a href=
        "https://w3c.github.io/mediacapture-main/archives/20160513/getusermedia.html#idl-def-MediaTrackSettings">
        <dfn>MediaTrackSettings</dfn></a></code>, <code><a href=
        "https://w3c.github.io/mediacapture-main/archives/20160513/getusermedia.html#idl-def-MediaTrackConstraints">
        <dfn>MediaTrackConstraints</dfn></a></code>, <code><a href=
        "https://w3c.github.io/mediacapture-main/archives/20160513/getusermedia.html#idl-def-MediaTrackSupportedConstraints">
        <dfn>MediaTrackSupportedConstraints</dfn></a></code>, <code><a href=
        "https://w3c.github.io/mediacapture-main/archives/20160513/getusermedia.html#idl-def-MediaTrackCapabilities">
        <dfn>MediaTrackCapabilities</dfn></a></code>, and <code><a href=
        "https://w3c.github.io/mediacapture-main/archives/20160513/getusermedia.html#idl-def-MediaTrackConstraintSet">
        <dfn>MediaTrackConstraintSet</dfn></a></code> dictionaries this
        specification extends are defined in [[!GETUSERMEDIA]].
      </p>
      <p>
        The <code><a href=
        "https://w3c.github.io/mediacapture-main/#dom-mediadevices-getusermedia">
        <dfn>getUserMedia()</dfn></a></code>, <code><a href=
        "https://w3c.github.io/mediacapture-main/#dfn-getsettings"><dfn>getSettings()</dfn></a></code>
        methods and the <code><a href=
        "https://w3c.github.io/mediacapture-main/#idl-def-NavigatorUserMediaSuccessCallback">
        <dfn>NavigatorUserMediaSuccessCallback</dfn></a></code> callback are
        defined in [[!GETUSERMEDIA]].
      </p>
      <p>
        The concepts <a href=
        "https://w3c.github.io/mediacapture-main/#track-muted"><dfn>muted</dfn></a>,
        <a href=
        "https://w3c.github.io/mediacapture-main/#track-enabled"><dfn>disabled</dfn></a>,
        and <code><a href=
        "https://w3c.github.io/mediacapture-main/archives/20160513/getusermedia.html#event-mediastreamtrack-overconstrained">
        <dfn>overconstrained</dfn></a></code> as applied to
        <a>MediaStreamTrack</a> are defined in [[!GETUSERMEDIA]].
      </p>
      <p>
        The terms <a href=
        "https://w3c.github.io/mediacapture-main/#dfn-source"><dfn>source</dfn></a>
        and <a href=
        "https://w3c.github.io/mediacapture-main/#dfn-consumer"><dfn>consumer</dfn></a>
        are defined in [[!GETUSERMEDIA]].
      </p>
      <p>
        The <code><a href=
        "https://w3c.github.io/mediacapture-main/#idl-def-MediaDeviceKind"><dfn>
        MediaDeviceKind</dfn></a></code> enumeration is defined in
        [[!GETUSERMEDIA]].
      </p>
      <p>
        The <code><a href=
        "https://html.spec.whatwg.org/multipage/embedded-content.html#the-video-element">
        <dfn>video</dfn></a></code> element and <code><a href=
        "https://html.spec.whatwg.org/multipage/scripting.html#imagedata"><dfn>ImageData</dfn></a></code>
        (and its <code><a href=
        "%20https://html.spec.whatwg.org/multipage/scripting.html#dom-imagedata-data">
        <dfn>data</dfn></a></code> attribute and <a href=
        "https://html.spec.whatwg.org/multipage/scripting.html#canvas-pixel-arraybuffer">
        <dfn>Canvas Pixel <code>ArrayBuffer</code></dfn></a>), <code><a href=
        "https://html.spec.whatwg.org/multipage/embedded-content.html#videotrack">
        <dfn>VideoTrack</dfn></a></code>, <code><a href=
        "%20https://html.spec.whatwg.org/multipage/embedded-content.html#htmlmediaelement">
        <dfn>HTMLMediaElement</dfn></a></code> (and its <code><a href=
        "%20https://html.spec.whatwg.org/multipage/embedded-content.html#dom-media-srcobject">
        <dfn>srcObject</dfn></a></code> attribute), <code><a href=
        "%20https://html.spec.whatwg.org/multipage/embedded-content.html#htmlvideoelement">
        <dfn>HTMLVideoElement</dfn></a></code> interfaces and the
        <code><a href="%20https://html.spec.whatwg.org/multipage/scripting.html#canvasimagesource">
        <dfn>CanvasImageSource</dfn></a></code> enum are defined in [[!HTML]].
      </p>
      <p>
        The terms <a href=
        "https://html.spec.whatwg.org/multipage/embedded-content.html#media-data">
        <dfn>media data</dfn></a>, <a href=
        "%20https://html.spec.whatwg.org/multipage/embedded-content.html#media-provider-object">
        <dfn>media provider object</dfn></a> , <a href=
        "https://html.spec.whatwg.org/multipage/embedded-content.html#assigned-media-provider-object">
        <dfn>assigned media provider object</dfn></a>, and the concept <a href=
        "https://html.spec.whatwg.org/multipage/embedded-content.html#potentially-playing">
        <dfn>potentially playing</dfn></a> are defined in [[!HTML]].
      </p>
      <p>
        The term <a href=
        "https://w3c.github.io/permissions/#permission"><dfn>permission</dfn></a>
        and the permission name <code><a href=
        "https://w3c.github.io/permissions/#dom-permissionname-camera">"<dfn>camera</dfn>"</a></code>
        are defined in [[!PERMISSIONS]].
      </p>
      <p>
        The <code><a href=
        "https://heycam.github.io/webidl/#idl-DataView"><dfn>DataView</dfn></a></code>,
        <code><a href=
        "https://heycam.github.io/webidl/#idl-Uint8ClampedArray"><dfn>Uint8ClampedArray</dfn></a></code>,
        and <code><a href=
        "https://heycam.github.io/webidl/#idl-Uint16Array"><dfn>Uint16Array</dfn></a></code>
        buffer source types are defined in [[WEBIDL]].
      </p>
    </section>
    <section>
      <h2>
        Terminology
      </h2>
      <p>
        The term <dfn>depth+color stream</dfn> means a <a>MediaStream</a>
        object that contains one or more <a>MediaStreamTrack</a> objects whose
        <code>videoKind</code> of <code>Settings</code> is "<code>depth</code>"
        (<a>depth stream track</a>) and one or more <a>MediaStreamTrack</a>
        objects whose <code>videoKind</code> of <code>Settings</code> is
        "<code>color</code>" (<a>color stream track</a>).
      </p>
      <p>
        The term <dfn>depth-only stream</dfn> means a <a>MediaStream</a> object
        that contains one or more <a>MediaStreamTrack</a> objects whose
        <code>videoKind</code> of <code>Settings</code> is "<code>depth</code>"
        (<a>depth stream track</a>) only.
      </p>
      <p>
        The term <dfn>color-only stream</dfn> means a <a>MediaStream</a> object
        that contains one or more <a>MediaStreamTrack</a> objects whose
        <code>videoKind</code> of <code>Settings</code> is "<code>color</code>"
        (<a>color stream track</a>) only, and optionally of kind
        "<code>audio</code>".
      </p>
      <p>
        The term <dfn>depth stream track</dfn> means a <a>MediaStreamTrack</a>
        object whose <code>videoKind</code> of <code>Settings</code> is
        "<code>depth</code>". It represents a media stream track whose
        <a>source</a> is a depth camera.
      </p>
      <p>
        The term <dfn>color stream track</dfn> means a <a>MediaStreamTrack</a>
        object whose <code>videoKind</code> of <code>Settings</code> is
        "<code>color</code>". It represents a media stream track whose
        <a>source</a> is a color camera.
      </p>
      <section>
        <h2>
          Depth map
        </h2>
        <p>
          A <dfn>depth map</dfn> is an abstract representation of a frame of a
          <a>depth stream track</a>. A <a>depth map</a> is an image that
          contains information relating to the distance of the surfaces of
          scene objects from a viewpoint. A <a>depth map</a> consists of pixels
          referred to as <dfn data-lt="depth map value">depth map values</dfn>.
          An <dfn>invalid depth map value</dfn> is 0 (the user agent is unable
          to acquire depth information for the given pixel for any reason).
        </p>
        <p>
          A <a>depth map</a> has an associated <dfn>near value</dfn> which is a
          double. It represents the minimum range in meters.
        </p>
        <p>
          A <a>depth map</a> has an associated <dfn>far value</dfn> which is a
          double. It represents the maximum range in meters.
        </p>
        <p>
          A <a>depth map</a> has an associated <dfn>horizontal focal
          length</dfn> which is a double. It represents the horizontal focal
          length of the depth camera, in pixels.
        </p>
        <p>
          A <a>depth map</a> has an associated <dfn>vertical focal length</dfn>
          which is a double. It represents the vertical focal length of the
          depth camera, in pixels.
        </p>
        <p>
          The data type of a <a>depth map</a> is 16-bit unsigned integer. The
          algorithm to <dfn>convert the depth map value to grayscale</dfn>,
          given a <a>depth map value</a> <var>d</var>, is as follows:
        </p>
        <ol>
          <li>Let <var>near</var> be the the <a>near value</a>.
          </li>
          <li>Let <var>far</var> be the the <a>far value</a>.
          </li>
          <li>If the given <a>depth map value</a> <var>d</var> is unknown or
          invalid, then return the <a>invalid depth map value</a>.
          </li>
          <li>Apply the <a>rules to convert using range linear</a> to
          <var>d</var> to obtain quantized value <var>d<sub>16bit</sub>.</var>
          </li>
          <li>Return <var>d<sub>16bit</sub></var>.
          </li>
        </ol>
        <p>
          The <dfn>rules to convert using range linear</dfn> are as given in
          the following formula:
        </p>
        <p>
          `d_(n) = (d - n ear) / (far - n ear)`
        </p>
        <p>
          `d_(16bit) = floor(d_(n) * 65535)`
        </p>
        <div class="note">
          <p>
            The depth measurement <var>d</var> (in meter units) is recovered by
            solving the <a>rules to convert using range linear</a> for
            <var>d</var> as follows:
          </p>
          <ol>
            <li>If <var>d<sub>16bit</sub></var> is 0, let <var>d</var> be an
            <a>invalid depth map value</a>, and return it.
            </li>
            <li>Otherwise, given <var>d<sub>16bit</sub></var>, <var>near</var>
            <a>near value</a> and <var>far</var> <a>far value</a>, normalize
            <var>d<sub>16bit</sub></var> to [0, 1] range:
              <p>
                `d_(n) = d_(16bit) / 65535`
              </p>
            </li>
            <li>Solve the <a>rules to convert using range linear</a> for <var>
              d</var>:
              <p>
                `d = (d_(n) * (far - n ear)) + n ear`
              </p>
            </li>
            <li>Return <var>d</var>.
            </li>
          </ol>
        </div>
      </section>
    </section>
    <section>
      <h2>
        Extensions
      </h2>
      <section>
        <h2>
          <code><a>MediaTrackSupportedConstraints</a></code> dictionary
        </h2>
        <pre class="idl">
          partial dictionary MediaTrackSupportedConstraints {
              boolean videoKind = true;
              boolean depthNear = true;
              boolean depthFar = true;
              boolean focalLengthX = true;
              boolean focalLengthY = true;
          };
</pre>
        <section>
          <h2>
            Dictionary <a class="idlType">MediaTrackSupportedConstraints</a>
            Members
          </h2>
          <dl data-link-for="MediaTrackSupportedConstraints" data-dfn-for=
          "MediaTrackSupportedConstraints" class="dictionary-members">
            <dt>
              <dfn data-dfn-for=
              "MediaTrackSupportedConstraints"><code>videoKind</code></dfn> of
              type <span class="idlMemberType"><a>boolean</a></span>,
              defaulting to <code>true</code>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-videoKind">videoKind</a></code> for details.
            </dd>
            <dt>
              <dfn data-dfn-for=
              "MediaTrackSupportedConstraints"><code>depthNear</code></dfn> of
              type <span class="idlMemberType"><a>boolean</a></span>,
              defaulting to <code>true</code>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-depthNear">depthNear</a></code> for details.
            </dd>
            <dt>
              <dfn data-dfn-for=
              "MediaTrackSupportedConstraints"><code>depthFar</code></dfn> of
              type <span class="idlMemberType"><a>boolean</a></span>,
              defaulting to <code>true</code>
            </dt>
            <dd>
              See <code><a href="#def-constraint-depthFar">depthFar</a></code>
              for details.
            </dd>
            <dt>
              <dfn data-dfn-for=
              "MediaTrackSupportedConstraints"><code>focalLengthX</code></dfn>
              of type <span class="idlMemberType"><a>boolean</a></span>,
              defaulting to <code>true</code>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-focalLengthX">focalLengthX</a></code> for
              details.
            </dd>
            <dt>
              <dfn data-dfn-for=
              "MediaTrackSupportedConstraints"><code>focalLengthY</code></dfn>
              of type <span class="idlMemberType"><a>boolean</a></span>,
              defaulting to <code>true</code>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-focalLengthY">focalLengthY</a></code> for
              details.
            </dd>
          </dl>
        </section>
      </section>
      <section>
        <h2>
          <code><a>MediaTrackCapabilities</a></code> dictionary
        </h2>
        <pre class="idl">
          partial dictionary MediaTrackCapabilities {
              DOMString videoKind;
              (double or DoubleRange) depthNear;
              (double or DoubleRange) depthFar;
              (double or DoubleRange) focalLengthX;
              (double or DoubleRange) focalLengthY;
          };
</pre>
        <section>
          <h2>
            Dictionary <a class="idlType">MediaTrackCapabilities</a> Members
          </h2>
          <dl data-link-for="MediaTrackCapabilities" data-dfn-for=
          "MediaTrackCapabilities" class="dictionary-members">
            <dt>
              <dfn><code>videoKind</code></dfn> of type <span class=
              "idlMemberType"><a>DOMString</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-videoKind">videoKind</a></code> for details.
            </dd>
            <dt>
              <dfn><code>depthNear</code></dfn> of type <span class=
              "idlMemberType"><a>(doule or DoubleRange)</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-depthNear">depthNear</a></code> for details.
            </dd>
            <dt>
              <dfn><code>depthFar</code></dfn> of type <span class=
              "idlMemberType"><a>(doule or DoubleRange)</a></span>
            </dt>
            <dd>
              See <code><a href="#def-constraint-depthFar">depthFar</a></code>
              for details.
            </dd>
            <dt>
              <dfn><code>focalLengthX</code></dfn> of type <span class=
              "idlMemberType"><a>(doule or DoubleRange)</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-focalLengthX">focalLengthX</a></code> for
              details.
            </dd>
            <dt>
              <dfn><code>focalLengthY</code></dfn> of type <span class=
              "idlMemberType"><a>(doule or DoubleRange)</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-focalLengthY">focalLengthY</a></code> for
              details.
            </dd>
          </dl>
        </section>
      </section>
      <section>
        <h2>
          MediaTrackConstraints
        </h2>
        <pre class="idl">
          partial dictionary MediaTrackConstraintSet {
              ConstrainDOMString videoKind;
              ConstrainDouble depthNear;
              ConstrainDouble depthFar;
              ConstrainDouble focalLengthX;
              ConstrainDouble focalLengthY;
          };
</pre>
        <section>
          <h2>
            Dictionary <a class="idlType">MediaTrackConstraintSet</a> Members
          </h2>
          <dl data-link-for="MediaTrackConstraintSet" data-dfn-for=
          "MediaTrackConstraintSet" class="dictionary-members">
            <dt>
              <dfn><code>videoKind</code></dfn> of type <span class=
              "idlMemberType"><a>ConstrainDOMString</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-videoKind">videoKind</a></code> for details.
            </dd>
            <dt>
              <dfn><code>depthNear</code></dfn> of type <span class=
              "idlMemberType"><a>ConstrainDouble</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-depthNear">depthNear</a></code> for details.
            </dd>
            <dt>
              <dfn><code>depthFar</code></dfn> of type <span class=
              "idlMemberType"><a>ConstrainDouble</a></span>
            </dt>
            <dd>
              See <code><a href="#def-constraint-depthFar">depthFar</a></code>
              for details.
            </dd>
            <dt>
              <dfn><code>focalLengthX</code></dfn> of type <span class=
              "idlMemberType"><a>ConstrainDouble</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-focalLengthX">focalLengthX</a></code> for
              details.
            </dd>
            <dt>
              <dfn><code>focalLengthY</code></dfn> of type <span class=
              "idlMemberType"><a>ConstrainDouble</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-focalLengthY">focalLengthY</a></code> for
              details.
            </dd>
          </dl>
        </section>
      </section>
      <section>
        <h2>
          <code>MediaTrackSettings</code> dictionary
        </h2>
        <pre class="idl">
          partial dictionary MediaTrackSettings {
              DOMString           videoKind;
              double              depthNear;
              double              depthFar;
              double              focalLengthX;
              double              focalLengthY;
          };
</pre>
        <section>
          <h2>
            Dictionary <a class="idlType">MediaTrackSettings</a> Members
          </h2>
          <dl data-link-for="MediaTrackSettings" data-dfn-for=
          "MediaTrackSettings" class="dictionary-members">
            <dt>
              <dfn><code>videoKind</code></dfn> of type <span class=
              "idlMemberType"><a>DOMString</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-videoKind">videoKind</a></code> for details.
            </dd>
            <dt>
              <dfn><code>depthNear</code></dfn> of type <span class=
              "idlMemberType"><a>double</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-depthNear">depthNear</a></code> for details.
            </dd>
            <dt>
              <dfn><code>depthFar</code></dfn> of type <span class=
              "idlMemberType"><a>double</a></span>
            </dt>
            <dd>
              See <code><a href="#def-constraint-depthFar">depthFar</a></code>
              for details.
            </dd>
            <dt>
              <dfn><code>focalLengthX</code></dfn> of type <span class=
              "idlMemberType"><a>double</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-focalLengthX">focalLengthX</a></code> for
              details.
            </dd>
            <dt>
              <dfn><code>focalLengthY</code></dfn> of type <span class=
              "idlMemberType"><a>double</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-focalLengthY">focalLengthY</a></code> for
              details.
            </dd>
          </dl>
        </section>
      </section>
      <section>
        <h2>
          Constrainable properties
        </h2>
        <p>
          The following constrainable properties are defined to apply only to
          video <code><a>MediaStreamTrack</a></code> objects:
        </p>
        <table class="simple">
          <thead>
            <tr>
              <th>
                Property Name
              </th>
              <th>
                Values
              </th>
              <th>
                Notes
              </th>
            </tr>
          </thead>
          <tbody>
            <tr id="def-constraint-videoKind">
              <td>
                <dfn>videoKind</dfn>
              </td>
              <td>
                <code>ConstrainDOMString</code>
              </td>
              <td>
                This string should be one of the members of
                <dfn><code><a>VideoKindEnum</a></code></dfn>. The members
                describe the kind of video that the camera can capture. Note
                that <code>getConstraints</code> may not return exactly the
                same string for strings not in this enum. This preserves the
                possibility of using a future version of WebIDL enum for this
                property.
              </td>
            </tr>
          </tbody>
        </table>
        <div>
          <pre class="idl">
enum VideoKindEnum {
    "color",
    "depth"
};
</pre>
          <table data-link-for="VideoKindEnum" data-dfn-for="VideoKindEnum"
          class="simple">
            <tbody>
              <tr>
                <th colspan="2">
                  Enumeration description
                </th>
              </tr>
              <tr>
                <td>
                  <dfn><code id=
                  "idl-def-VideoKindEnum.color">color</code></dfn>
                </td>
                <td>
                  <p>
                    The source is capturing color images.
                  </p>
                </td>
              </tr>
              <tr>
                <td>
                  <dfn><code id=
                  "idl-def-VideoKindEnum.depth">depth</code></dfn>
                </td>
                <td>
                  <p>
                    The source is capturing depth maps.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </div>
        <div class="note">
          If the user agent requests a combined <a>depth+color stream</a>, the
          devices in the constraint should be satisfied as belonging to the
          same group or physical device. The decision to select and satisfy
          which device pair is left up to the implementation.
        </div>
        <p>
          The <a>MediaStream</a> <a>consumer</a> for the <a>depth-only
          stream</a> and <a>depth+color stream</a> is <a href=
          "#the-video-element">the <code>video</code> element</a> [[!HTML]].
        </p>
        <div class="note">
          New <a>consumer</a>s may be added in a future version of this
          specification.
        </div>
        <p>
          If a <a>MediaStreamTrack</a> whose <code>videoKind</code> of
          <code>Settings</code> is <a>muted</a> or <a>disabled</a>, it MUST
          render frames as if all the pixels would be 0.
        </p>
        <section class="informative">
          <h3>
            Implementation considerations
          </h3>
          <p>
            A <a>color stream track</a> and a <a>depth stream track</a> can be
            combined into one <a>depth+color stream</a>. The rendering of the
            two tracks are intended to be synchronized. The resolution of the
            two tracks are intended to be same. And the coordination of the two
            tracks are intended to be calibrated. These are not hard
            requirements, since it might not be possible to synchronize tracks
            from sources.
          </p>
        </section>
        <p>
          The following constrainable properties are defined to apply only to
          <a>depth stream track</a>s
        </p>
        <table class="simple">
          <thead>
            <tr>
              <th>
                Property Name
              </th>
              <th>
                Values
              </th>
              <th>
                Notes
              </th>
            </tr>
          </thead>
          <tbody>
            <tr id="def-constraint-depthNear">
              <td>
                <dfn>depthNear</dfn>
              </td>
              <td>
                <code>ConstrainDouble</code>
              </td>
              <td>
                The <a>near value</a>, in meters.
              </td>
            </tr>
            <tr id="def-constraint-depthFar">
              <td>
                <dfn>depthFar</dfn>
              </td>
              <td>
                <code>ConstrainDouble</code>
              </td>
              <td>
                The <a>far value</a>, in meters.
              </td>
            </tr>
            <tr id="def-constraint-focalLengthX">
              <td>
                <dfn>focalLengthX</dfn>
              </td>
              <td>
                <code>ConstrainDouble</code>
              </td>
              <td>
                The <a>horizontal focal length</a>, in pixels.
              </td>
            </tr>
            <tr id="def-constraint-focalLengthY">
              <td>
                <dfn>focalLengthY</dfn>
              </td>
              <td>
                <code>ConstrainDouble</code>
              </td>
              <td>
                The <a>vertical focal length</a>, in pixels.
              </td>
            </tr>
          </tbody>
        </table>
        <p>
          The <code>depthNear</code> and <code>depthFar</code> constrainable
          properties, when set, allow the implementation to pick the best depth
          camera mode optimized for the range <code>[depthNear,
          depthFar]</code> and help minimize the error introduced by the lossy
          conversion from the depth value <var>d</var> to a quantized
          d<sub>8bit</sub> and back to an approximation of the depth value
          <var>d</var>.
        </p>
        <p>
          If the <code>depthFar</code> property's value is less than the
          <code>depthNear</code> property's value, the <a>depth stream
          track</a> is <a>overconstrained</a>.
        </p>
        <p>
          If the <a>near value</a>, <a>far value</a>, <a>horizontal focal
          length</a> or <a>vertical focal length</a> is fixed due to a hardware
          or software limitation, the corresponding constrainable property's
          value MUST be set to the value reported by the underlying
          implementation. (For example, the focal lengths of the lens may be
          fixed, or the underlying platform may not expose the focal length
          information.)
        </p>
      </section>
      <section>
        <h2>
          <code>WebGLRenderingContext</code> interface
        </h2>
        <section class="informative">
          <h3>
            Implementation considerations
          </h3>
          <div class="note">
            This section is currently work in progress, and subject to change.
          </div>
          <p>
            A <code>video</code> element whose source is a
            <a><code>MediaStream</code></a> object containing a <a>depth stream
            track</a> may be uploaded to a WebGL texture of format
            <code>RGB</code> and type <code>UNSIGNED_BYTE</code>. [[WEBGL]]
          </p>
          <p>
            For each pixel of this WebGL texture, the R component represents
            the lower 8 bit value of 16 bit depth value, the G component
            represents the upper 8 bit value of 16 bit depth value and the
            value in B component is not defined.
          </p>
        </section>
      </section>
    </section>
    <section class="informative">
      <h2>
        Examples
      </h2>
      <h3>
        Playback of depth and color streams from same device group.
      </h3>
      <pre class="example highlight">
navigator.mediaDevices.getUserMedia({
  video: {videoKind: {exact: "color"}, groupId: {exact: id}}
}).then(function (stream) {
    // Wire the media stream into a &lt;video&gt; element for playback.
    // The RGB video is rendered.
    var video = document.querySelector('#video');
    video.srcObject = stream;
    video.play();
  }
);

navigator.mediaDevices.getUserMedia({
  video: {videoKind: {exact: "depth"}, groupId: {exact: id}}
}).then(function (stream) {
    // Wire the depth-only stream into another &lt;video&gt; element for playback.
    // The depth information is rendered in its grayscale representation.
    var depthVideo = document.querySelector('#depthVideo');
    depthVideo.srcObject = stream;
    depthVideo.play();
  }
);
</pre>
      <h3>
        WebGL Fragment Shader based post-processing
      </h3>
      <pre class="example highlight">
// This code sets up a video element from a depth stream, uploads it to a WebGL
// texture, and samples that texture in the fragment shader, reconstructing the
// 16-bit depth values from the red and green channels.
navigator.mediaDevices.getUserMedia({
  video: {videoKind: {exact: "depth"}}
}).then(function (stream) {
  // wire the stream into a &lt;video&gt; element for playback
  var depthVideo = document.querySelector('#depthVideo');
  depthVideo.srcObject = stream;
  depthVideo.play();
}).catch(function (reason) {
  // handle gUM error here
});

// ... later, in the rendering loop ...
gl.texImage2D(
   gl.TEXTURE_2D,
   0,
   gl.RGB,
   gl.RGB,
   gl.UNSIGNED_BYTE,
   depthVideo
);

&lt;script id="fragment-shader" type="x-shader/x-fragment"&gt;
  varying vec2 v_texCoord;
  // u_tex points to the texture unit containing the depth texture.
  uniform sampler2D u_tex;
  uniform float far;
  uniform float near;
  void main() {
    vec4 floatColor = texture2D(u_tex, v_texCoord);
    float dn = floatColor.r;
    float depth = 0.;
    depth = far * near / ( far - dn * ( far - near));
    // ...
  }
&lt;/script&gt;
</pre>
    </section>
    <section class="informative">
      <h2>
        Privacy and security considerations
      </h2>
      <p>
        The <a href=
        "https://w3c.github.io/mediacapture-main/#privacy-and-security-considerations">
        privacy and security considerations</a> discussed in [[!GETUSERMEDIA]]
        apply to this extension specification.
      </p>
    </section>
    <section class="appendix">
      <h2>
        Acknowledgements
      </h2>
      <p>
        Thanks to everyone who contributed to the <a href=
        "https://www.w3.org/wiki/Media_Capture_Depth_Stream_Extension">Use
        Cases and Requirements</a>, sent feedback and comments. Special thanks
        to Ningxin Hu for experimental implementations, as well as to the
        Project Tango for their experiments.
      </p>
    </section>
  </body>
</html>
