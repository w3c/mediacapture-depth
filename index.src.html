<!DOCTYPE html>
<html>
  <head>
    <title>
      Media Capture Depth Stream Extensions
    </title>
    <meta charset="utf-8">
    <script src="https://www.w3.org/Tools/respec/respec-w3c-common" class=
    "remove">
</script>
    <script class="remove">

      var respecConfig = {
        specStatus: "ED",
        shortName: "mediacapture-depth",
        previousPublishDate: "2015-12-08",
        previousMaturity: "WD",
        edDraftURI: "https://w3c.github.io/mediacapture-depth/",
        editors: [
            {
              w3cid:      "41974",
              name:       "Anssi Kostiainen",
              company:    "Intel",
              companyURL: "http://www.intel.com/"
            },
            {
              w3cid:      "68202",
              name:       "Ningxin Hu",
              company:    "Intel",
              companyURL: "http://www.intel.com/"
            },
            {
              w3cid:      "76096",
              name:       "Rob Manson",
              company:    "Invited Expert"
            }
        ],
        wg: [
          "Device and Sensors Working Group",
          "Web Real-Time Communications Working Group"
        ],
        wgURI: [
          "https://www.w3.org/2009/dap/",
          "https://www.w3.org/2011/04/webrtc/"
        ],
        wgPublicList: "public-media-capture",
        wgPatentURI: [
          "https://www.w3.org/2004/01/pp-impl/47318/status",
          "https://www.w3.org/2004/01/pp-impl/43696/status"
        ],
        otherLinks: [{
        key: "Participate",
        data: [
          {
            value: "public-media-capture@w3.org",
            href: "https://lists.w3.org/Archives/Public/public-media-capture/"
          },
          {
            value: "GitHub w3c/mediacapture-depth",
            href: "https://github.com/w3c/mediacapture-depth/"
          },
          {
            value: "GitHub w3c/mediacapture-depth/issues",
            href: "https://github.com/w3c/mediacapture-depth/issues"
          },
          {
            value: "GitHub w3c/mediacapture-depth/commits",
            href: "https://github.com/w3c/mediacapture-depth/commits/"
          }
        ]
        }],
        localBiblio: {
          "MEDIACAPTURE-WORKER": {
              title:     "Media Capture Stream with Worker",
              href:      "https://w3c.github.io/mediacapture-worker/",
              authors:  [
                         "Chia-hung Tai",
                         "Robert O'Callahan",
                         "Tzuhao Kuo",
                         "Anssi Kostiainen"
              ],
              status:    "ED",
              publisher: "W3C"
          }
        }
    };

    </script>
    <script src=
    "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_CHTML">
</script>
  </head>
  <body>
    <section id="abstract">
      <p>
        This specification <a href=
        "https://w3c.github.io/mediacapture-main/#extensibility">extends</a>
        the <em>Media Capture and Streams</em> specification [[!GETUSERMEDIA]]
        to allow a <a>depth-only stream</a> or combined <a>depth+color
        stream</a> to be requested from the web platform using APIs familiar to
        web authors.
      </p>
    </section>
    <section id="sotd">
      <p>
        This extensions specification defines a new media type and
        constrainable property per <a href=
        "https://w3c.github.io/mediacapture-main/#extensibility">Extensibility</a>
        guidelines of the <em>Media Capture and Streams</em> specification
        [[!GETUSERMEDIA]]. Horizontal reviews and feedback from early
        implementations of this specification are encouraged.
      </p>
    </section>
    <section>
      <h2>
        Introduction
      </h2>
      <p>
        Depth cameras are increasingly being integrated into devices such as
        phones, tablets, and laptops. Depth cameras provide a <a>depth map</a>,
        which conveys the distance information between points on an object's
        surface and the camera. With depth information, web content and
        applications can be enhanced by, for example, the use of hand gestures
        as an input mechanism, or by creating 3D models of real-world objects
        that can interact and integrate with the web platform. Concrete
        applications of this technology include more immersive gaming
        experiences, more accessible 3D video conferences, and augmented
        reality, to name a few.
      </p>
      <p>
        To bring depth capability to the web platform, this specification
        <a href=
        "https://w3c.github.io/mediacapture-main/#extensibility">extends</a>
        the <a>MediaStream</a> interface [[!GETUSERMEDIA]] to enable it to also
        contain depth-based <a>MediaStreamTrack</a>s. A depth-based
        <a>MediaStreamTrack</a>, referred to as a <a>depth stream track</a>,
        represents an abstraction of a stream of frames that can each be
        converted to objects which contain an array of pixel data, where each
        pixel represents the distance between the camera and the objects in the
        scene for that point in the array. A <a>MediaStream</a> object that
        contains one or more <a>depth stream track</a>s is referred to as a
        <a>depth-only stream</a> or <a>depth+color stream</a>.
      </p>
      <p>
        Depth cameras usually produce 16-bit depth values per pixel, so this
        specification defines a 16-bit grayscale representation of a <a>depth
        map</a>.
      </p>
    </section>
    <section>
      <h2>
        Use cases and requirements
      </h2>
      <p>
        This specification attempts to address the <a href=
        "https://www.w3.org/wiki/Media_Capture_Depth_Stream_Extension">Use
        Cases and Requirements</a> for accessing depth stream from a depth
        camera. See also the <a href=
        "https://www.w3.org/wiki/Media_Capture_Depth_Stream_Extension#Examples">
        Examples</a> section for concrete usage examples.
      </p>
    </section>
    <section id="conformance">
      <p>
        This specification defines conformance criteria that apply to a single
        product: the <dfn>user agent</dfn> that implements the interfaces that
        it contains.
      </p>
      <p>
        Implementations that use ECMAScript to implement the APIs defined in
        this specification must implement them in a manner consistent with the
        ECMAScript Bindings defined in the Web IDL specification [[!WEBIDL]],
        as this specification uses that specification and terminology.
      </p>
    </section>
    <section>
      <h2>
        Dependencies
      </h2>
      <p>
        The <dfn data-cite=
        "!GETUSERMEDIA#idl-def-MediaStreamTrack"><code>MediaStreamTrack</code></dfn>
        and <dfn data-cite=
        "!GETUSERMEDIA#idl-def-MediaStream"><code>MediaStream</code></dfn>
        interfaces this specification extends are defined in [[!GETUSERMEDIA]].
      </p>
      <p>
        The <dfn data-cite=
        "!GETUSERMEDIA#idl-def-Constraints"><code>Constraints</code></dfn>,
        <dfn data-cite=
        "GETUSERMEDIA#idl-def-MediaTrackSettings"><code>MediaTrackSettings</code></dfn>,
        <dfn data-cite=
        "!GETUSERMEDIA#idl-def-MediaTrackConstraints"><code>MediaTrackConstraints</code></dfn>,
        <dfn data-cite=
        "!GETUSERMEDIA#idl-def-MediaTrackSupportedConstraints"><code>MediaTrackSupportedConstraints</code></dfn>,
        <dfn data-cite=
        "!GETUSERMEDIA#idl-def-MediaTrackCapabilities"><code>MediaTrackCapabilities</code></dfn>,
        and <dfn data-cite=
        "!GETUSERMEDIA#idl-def-MediaTrackConstraintSet"><code>MediaTrackConstraintSet</code></dfn>
        dictionaries this specification extends are defined in
        [[!GETUSERMEDIA]].
      </p>
      <p>
        The <dfn data-cite=
        "!GETUSERMEDIA#dom-mediadevices-getusermedia"><code>getUserMedia()</code></dfn>,
        <dfn data-cite=
        "!GETUSERMEDIA#dfn-getsettings"><code>getSettings()</code></dfn>
        methods and the <dfn data-cite=
        "!GETUSERMEDIA#idl-def-NavigatorUserMediaSuccessCallback"><code>NavigatorUserMediaSuccessCallback</code></dfn>
        callback are defined in [[!GETUSERMEDIA]].
      </p>
      <p>
        The concepts <dfn data-cite="!GETUSERMEDIA#track-muted">muted</dfn>,
        <dfn data-cite="!GETUSERMEDIA#track-enabled">disabled</dfn>, and
        <dfn data-cite=
        "!GETUSERMEDIA#event-mediastreamtrack-overconstrained"><code>overconstrained</code></dfn>
        as applied to <a>MediaStreamTrack</a> are defined in [[!GETUSERMEDIA]].
      </p>
      <p>
        The terms <dfn data-cite="!GETUSERMEDIA#dfn-source">source</dfn> and
        <dfn data-cite="!GETUSERMEDIA#dfn-consumer">consumer</dfn> are defined
        in [[!GETUSERMEDIA]].
      </p>
      <p>
        The <dfn data-cite=
        "!GETUSERMEDIA#idl-def-MediaDeviceKind"><code>MediaDeviceKind</code></dfn>
        enumeration is defined in [[!GETUSERMEDIA]].
      </p>
      <p>
        The <dfn data-cite="!HTML#the-video-element"><code>video</code></dfn>
        element and <dfn data-cite=
        "!HTML#imagedata"><code>ImageData</code></dfn> (and its <dfn data-cite=
        "!HTML#dom-imagedata-data"><code>data</code></dfn> attribute and
        <dfn data-cite="!HTML#canvas-pixel-arraybuffer">Canvas Pixel
        <code>ArrayBuffer</code></dfn>), <dfn data-cite=
        "!HTML#videotrack"><code>VideoTrack</code></dfn>, <dfn data-cite=
        "!HTML#htmlmediaelement"><code>HTMLMediaElement</code></dfn> (and its
        <dfn data-cite="!HTML#dom-media-srcobject"><code>srcObject</code></dfn>
        attribute), <dfn data-cite=
        "!HTML#htmlvideoelement"><code>HTMLVideoElement</code></dfn> interfaces
        and the <dfn data-cite=
        "!HTML#canvasimagesource"><code>CanvasImageSource</code></dfn> enum are
        defined in [[!HTML]].
      </p>
      <p>
        The terms <dfn data-cite="!HTML#media-data">media data</dfn>,
        <dfn data-cite="!HTML#media-provider-object">media provider
        object</dfn>, <dfn data-cite=
        "!HTML#assigned-media-provider-object">assigned media provider
        object</dfn>, and the concept <dfn data-cite=
        "!HTML#potentially-playing">potentially playing</dfn> are defined in
        [[!HTML]].
      </p>
      <p>
        The term <dfn data-cite="!PERMISSIONS#permission">permission</dfn> and
        the permission name "<dfn data-cite=
        "!PERMISSIONS#dom-permissionname-camera"><code>camera</code></dfn>" are
        defined in [[!PERMISSIONS]].
      </p>
      <p>
        The <dfn data-cite="!WEBIDL#idl-DataView"><code>DataView</code></dfn>,
        <dfn data-cite=
        "!WEBIDL#idl-Uint8ClampedArray"><code>Uint8ClampedArray</code></dfn>,
        and <code><dfn data-cite=
        "!WEBIDL#idl-Uint16Array">Uint16Array</dfn></code> buffer source types
        are defined in [[WEBIDL]].
      </p>
      <p>
        The meaning of dictionary member being <dfn data-cite=
        "!WEBIDL#dfn-present">present</dfn> or <dfn data-cite=
        "!WEBIDL#dfn-present">not present</dfn> is defined in [[WEBIDL]].
      </p>
    </section>
    <section>
      <h2>
        Terminology
      </h2>
      <p>
        The term <dfn>depth+color stream</dfn> means a <a>MediaStream</a>
        object that contains one or more <a>MediaStreamTrack</a> objects whose
        <code>videoKind</code> of <code>Settings</code> is "<code>depth</code>"
        (<a>depth stream track</a>) and one or more <a>MediaStreamTrack</a>
        objects whose <code>videoKind</code> of <code>Settings</code> is
        "<code>color</code>" (<a>color stream track</a>).
      </p>
      <p>
        The term <dfn>depth-only stream</dfn> means a <a>MediaStream</a> object
        that contains one or more <a>MediaStreamTrack</a> objects whose
        <code>videoKind</code> of <code>Settings</code> is "<code>depth</code>"
        (<a>depth stream track</a>) only.
      </p>
      <p>
        The term <dfn>color-only stream</dfn> means a <a>MediaStream</a> object
        that contains one or more <a>MediaStreamTrack</a> objects whose
        <code>videoKind</code> of <code>Settings</code> is "<code>color</code>"
        (<a>color stream track</a>) only, and optionally of kind
        "<code>audio</code>".
      </p>
      <p>
        The term <dfn>depth stream track</dfn> means a <a>MediaStreamTrack</a>
        object whose <code>videoKind</code> of <code>Settings</code> is
        "<code>depth</code>". It represents a media stream track whose
        <a>source</a> is a depth camera.
      </p>
      <p>
        The term <dfn>color stream track</dfn> means a <a>MediaStreamTrack</a>
        object whose <code>videoKind</code> of <code>Settings</code> is
        "<code>color</code>". It represents a media stream track whose
        <a>source</a> is a color camera.
      </p>
      <section>
        <h2>
          Depth map
        </h2>
        <p>
          A <dfn>depth map</dfn> is an abstract representation of a frame of a
          <a>depth stream track</a>. A <a>depth map</a> is an image that
          contains information relating to the distance of the surfaces of
          scene objects from a viewpoint. A <a>depth map</a> consists of pixels
          referred to as <dfn data-lt="depth map value">depth map values</dfn>.
          An <dfn>invalid depth map value</dfn> is 0 (the user agent is unable
          to acquire depth information for the given pixel for any reason).
        </p>
        <p>
          A <a>depth map</a> has an associated <dfn>near value</dfn> which is a
          double. It represents the minimum range in meters.
        </p>
        <p>
          A <a>depth map</a> has an associated <dfn>far value</dfn> which is a
          double. It represents the maximum range in meters.
        </p>
        <p>
          A <a>depth map</a> has an associated <dfn>horizontal focal
          length</dfn> which is a double. It represents the horizontal
          <dfn>focal length</dfn> of the depth camera, in pixels.
        </p>
        <p>
          A <a>depth map</a> has an associated <dfn>vertical focal length</dfn>
          which is a double. It represents the vertical focal length of the
          depth camera, in pixels.
        </p>
        <p>
          A <a>depth map</a> has an associated <dfn>principal point</dfn>,
          specified by <dfn>principal point x</dfn> and <dfn>principal point
          y</dfn> coordinates which are double. It is a concept defined in the
          pinhole camera model; a projection of perspective center to the image
          plane.
        </p>
        <p>
          A <a>depth map</a> has an associated <dfn>transformation from depth
          to video</dfn>, which is a <dfn>transformation matrix</dfn>
          represented by a <a>DepthToVideoTransform</a> dictionary. It is used
          to translate position in depth camera 3D coordinate system to RGB
          video stream's camera (identified by <dfn>videoDeviceId</dfn>) 3D
          coordinate system. After projecting depth 2D pixel coordinates to 3D
          space, we use this matrix to transform depth camera 3D space
          coordinates to RGB video camera 3D space.
        </p>
        <p>
          Both depth and color cameras usually introduce significant distortion
          caused by the camera and lens. While in some cases, the effects are
          not noticeable, these distortions cause errors in image analysis. To
          map <a>depth map</a> pixel values to corresponding color video track
          pixels, we use two <a>DistortionCoefficients</a> dictionaries:
          <dfn>deprojection distortion coefficients</dfn> and <dfn>projection
          distortion coefficients</dfn>.
        </p>
        <p>
          <a>Deprojection distortion coefficients</a> are used for compensating
          camera distortion when deprojecting 2D pixel coordinates to 3D space
          coordinates. <a>Projection distortion coefficients</a> are used in
          the opposite case, when projecting camera 3D space points to pixels.
          One track doesn't have both of the coefficients specified. The most
          common scenario is that the depth track has <a>deprojection
          distortion coefficients</a> or that the color video track has
          <a>projection distortion coefficients</a>. For the details, see
          <a>algorithm to map depth pixels to color pixels</a>.
        </p>
        <p>
          The data type of a <a>depth map</a> is 16-bit unsigned integer. The
          algorithm to <dfn>convert the depth map value to grayscale</dfn>,
          given a <a>depth map value</a> <var>d</var>, is as follows:
        </p>
        <ol>
          <li>Let <var>near</var> be the the <a>near value</a>.
          </li>
          <li>Let <var>far</var> be the the <a>far value</a>.
          </li>
          <li>If the given <a>depth map value</a> <var>d</var> is unknown or
          invalid, then return the <a>invalid depth map value</a>.
          </li>
          <li>Apply the <a>rules to convert using range linear</a> to
          <var>d</var> to obtain quantized value <var>d<sub>16bit</sub>.</var>
          </li>
          <li>Return <var>d<sub>16bit</sub></var>.
          </li>
        </ol>
        <p>
          The <dfn>rules to convert using range linear</dfn> are as given in
          the following formula:
        </p>
        <p>
          `d_(n) = (d - n ear) / (far - n ear)`
        </p>
        <p>
          `d_(16bit) = floor(d_(n) * 65535)`
        </p>
        <div class="note">
          <p>
            The depth measurement <var>d</var> (in meter units) is recovered by
            solving the <a>rules to convert using range linear</a> for
            <var>d</var> as follows:
          </p>
          <ol>
            <li>If <var>d<sub>16bit</sub></var> is 0, let <var>d</var> be an
            <a>invalid depth map value</a>, and return it.
            </li>
            <li>Otherwise, given <var>d<sub>16bit</sub></var>, <var>near</var>
            <a>near value</a> and <var>far</var> <a>far value</a>, normalize
            <var>d<sub>16bit</sub></var> to [0, 1] range:
              <p>
                `d_(n) = d_(16bit) / 65535`
              </p>
            </li>
            <li>Solve the <a>rules to convert using range linear</a> for <var>
              d</var>:
              <p>
                `d = (d_(n) * (far - n ear)) + n ear`
              </p>
            </li>
            <li>Return <var>d</var>.
            </li>
          </ol>
        </div>
      </section>
    </section>
    <section>
      <h2>
        Extensions
      </h2>
      <section>
        <h2>
          <a>MediaTrackSupportedConstraints</a> dictionary
        </h2>
        <pre class="idl">
          partial dictionary MediaTrackSupportedConstraints {
              boolean videoKind = true;
              boolean depthNear = true;
              boolean depthFar = true;
              boolean focalLengthX = true;
              boolean focalLengthY = true;
              boolean principalPointX = true;
              boolean principalPointY = true;
              boolean deprojectionDistortionCoefficients = false;
              boolean projectionDistortionCoefficients = false;
              boolean depthToVideoTransform = false;
          };
</pre>
        <section>
          <h2>
            Dictionary <a class="idlType">MediaTrackSupportedConstraints</a>
            Members
          </h2>
          <dl data-link-for="MediaTrackSupportedConstraints" data-dfn-for=
          "MediaTrackSupportedConstraints" class="dictionary-members">
            <dt>
              <dfn data-dfn-for=
              "MediaTrackSupportedConstraints"><code>videoKind</code></dfn> of
              type <span class="idlMemberType"><a>boolean</a></span>,
              defaulting to <code>true</code>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-videoKind">videoKind</a></code> for details.
            </dd>
            <dt>
              <dfn data-dfn-for=
              "MediaTrackSupportedConstraints"><code>depthNear</code></dfn> of
              type <span class="idlMemberType"><a>boolean</a></span>,
              defaulting to <code>true</code>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-depthNear">depthNear</a></code> for details.
            </dd>
            <dt>
              <dfn data-dfn-for=
              "MediaTrackSupportedConstraints"><code>depthFar</code></dfn> of
              type <span class="idlMemberType"><a>boolean</a></span>,
              defaulting to <code>true</code>
            </dt>
            <dd>
              See <code><a href="#def-constraint-depthFar">depthFar</a></code>
              for details.
            </dd>
            <dt>
              <dfn data-dfn-for=
              "MediaTrackSupportedConstraints"><code>focalLengthX</code></dfn>
              of type <span class="idlMemberType"><a>boolean</a></span>,
              defaulting to <code>true</code>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-focalLengthX">focalLengthX</a></code> for
              details.
            </dd>
            <dt>
              <dfn data-dfn-for=
              "MediaTrackSupportedConstraints"><code>focalLengthY</code></dfn>
              of type <span class="idlMemberType"><a>boolean</a></span>,
              defaulting to <code>true</code>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-focalLengthY">focalLengthY</a></code> for
              details.
            </dd>
            <dt>
              <dfn data-dfn-for=
              "MediaTrackSupportedConstraints"><code>principalPointX</code></dfn>
              of type <span class="idlMemberType"><a>boolean</a></span>,
              defaulting to <code>true</code>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-principalPointX">principalPointX</a></code> for
              details.
            </dd>
            <dt>
              <dfn data-dfn-for=
              "MediaTrackSupportedConstraints"><code>principalPointY</code></dfn>
              of type <span class="idlMemberType"><a>boolean</a></span>,
              defaulting to <code>true</code>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-principalPointY">principalPointY</a></code> for
              details.
            </dd>
            <dt>
              <dfn data-dfn-for=
              "MediaTrackSupportedConstraints"><code>deprojectionDistortionCoefficients</code></dfn>
              of type <span class="idlMemberType"><a>boolean</a></span> ,
              defaulting to <code>false</code>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-deprojectionDistortionCoefficients">deprojectionDistortionCoefficients</a></code>
              for details.
            </dd>
            <dt>
              <dfn data-dfn-for=
              "MediaTrackSupportedConstraints"><code>projectionDistortionCoefficients</code></dfn>
              of type <span class="idlMemberType"><a>boolean</a></span> ,
              defaulting to <code>false</code>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-projectionDistortionCoefficients">projectionDistortionCoefficients</a></code>
              for details.
            </dd>
            <dt>
              <dfn data-dfn-for=
              "MediaTrackSupportedConstraints"><code>depthToVideoTransform</code></dfn>
              of type <span class="idlMemberType"><a>boolean</a></span> ,
              defaulting to <code>false</code>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-depthToVideoTransform">depthToVideoTransform</a></code>
              for details.
            </dd>
          </dl>
        </section>
      </section>
      <section>
        <h2>
          <a>MediaTrackCapabilities</a> dictionary
        </h2>
        <pre class="idl">
          partial dictionary MediaTrackCapabilities {
              DOMString videoKind;
              (double or DoubleRange) depthNear;
              (double or DoubleRange) depthFar;
              (double or DoubleRange) focalLengthX;
              (double or DoubleRange) focalLengthY;
              (double or DoubleRange) principalPointX;
              (double or DoubleRange) principalPointY;
              boolean deprojectionDistortionCoefficients;
              boolean projectionDistortionCoefficients;
              boolean depthToVideoTransform;
          };
</pre>
        <section>
          <h2>
            Dictionary <a class="idlType">MediaTrackCapabilities</a> Members
          </h2>
          <dl data-link-for="MediaTrackCapabilities" data-dfn-for=
          "MediaTrackCapabilities" class="dictionary-members">
            <dt>
              <dfn><code>videoKind</code></dfn> of type <span class=
              "idlMemberType"><a>DOMString</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-videoKind">videoKind</a></code> for details.
            </dd>
            <dt>
              <dfn><code>depthNear</code></dfn> of type <span class=
              "idlMemberType"><a>(double or DoubleRange)</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-depthNear">depthNear</a></code> for details.
            </dd>
            <dt>
              <dfn><code>depthFar</code></dfn> of type <span class=
              "idlMemberType"><a>(double or DoubleRange)</a></span>
            </dt>
            <dd>
              See <code><a href="#def-constraint-depthFar">depthFar</a></code>
              for details.
            </dd>
            <dt>
              <dfn><code>focalLengthX</code></dfn> of type <span class=
              "idlMemberType"><a>(double or DoubleRange)</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-focalLengthX">focalLengthX</a></code> for
              details.
            </dd>
            <dt>
              <dfn><code>focalLengthY</code></dfn> of type <span class=
              "idlMemberType"><a>(double or DoubleRange)</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-focalLengthY">focalLengthY</a></code> for
              details.
            </dd>
            <dt>
              <dfn><code>principalPointX</code></dfn> of type <span class=
              "idlMemberType"><a>(double or DoubleRange)</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-principalPointX">principalPointX</a></code> for
              details.
            </dd>
            <dt>
              <dfn><code>principalPointY</code></dfn> of type <span class=
              "idlMemberType"><a>(double or DoubleRange)</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-principalPointY">principalPointY</a></code> for
              details.
            </dd>
            <dt>
              <dfn><code>deprojectionDistortionCoefficients</code></dfn> of
              type <span class="idlMemberType"><a>boolean</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-deprojectionDistortionCoefficients">deprojectionDistortionCoefficients</a></code>
              for details. Returns false if the source cannot provide this
              information.
            </dd>
            <dt>
              <dfn><code>projectionDistortionCoefficients</code></dfn> of type
              <span class="idlMemberType"><a>boolean</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-projectionDistortionCoefficients">projectionDistortionCoefficients</a></code>
              for details. Returns false if the source cannot provide this
              information.
            </dd>
            <dt>
              <dfn><code>depthToVideoTransform</code></dfn> of type
              <span class="idlMemberType"><a>boolean</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-depthToVideoTransform">depthToVideoTransform</a></code>
              for details. Returns false if the source cannot provide this
              information.
            </dd>
          </dl>
        </section>
      </section>
      <section>
        <h2>
          MediaTrackConstraints
        </h2>
        <pre class="idl">
          partial dictionary MediaTrackConstraintSet {
              ConstrainDOMString videoKind;
              ConstrainDouble depthNear;
              ConstrainDouble depthFar;
              ConstrainDouble focalLengthX;
              ConstrainDouble focalLengthY;
              ConstrainDouble principalPointX;
              ConstrainDouble principalPointY;
              ConstrainBoolean deprojectionDistortionCoefficients;
              ConstrainBoolean projectionDistortionCoefficients;
              ConstrainBoolean depthToVideoTransform;
          };
</pre>
        <section>
          <h2>
            Dictionary <a class="idlType">MediaTrackConstraintSet</a> Members
          </h2>
          <dl data-link-for="MediaTrackConstraintSet" data-dfn-for=
          "MediaTrackConstraintSet" class="dictionary-members">
            <dt>
              <dfn><code>videoKind</code></dfn> of type <span class=
              "idlMemberType"><a>ConstrainDOMString</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-videoKind">videoKind</a></code> for details.
            </dd>
            <dt>
              <dfn><code>depthNear</code></dfn> of type <span class=
              "idlMemberType"><a>ConstrainDouble</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-depthNear">depthNear</a></code> for details.
            </dd>
            <dt>
              <dfn><code>depthFar</code></dfn> of type <span class=
              "idlMemberType"><a>ConstrainDouble</a></span>
            </dt>
            <dd>
              See <code><a href="#def-constraint-depthFar">depthFar</a></code>
              for details.
            </dd>
            <dt>
              <dfn><code>focalLengthX</code></dfn> of type <span class=
              "idlMemberType"><a>ConstrainDouble</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-focalLengthX">focalLengthX</a></code> for
              details.
            </dd>
            <dt>
              <dfn><code>focalLengthY</code></dfn> of type <span class=
              "idlMemberType"><a>ConstrainDouble</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-focalLengthY">focalLengthY</a></code> for
              details.
            </dd>
            <dt>
              <dfn><code>principalPointX</code></dfn> of type <span class=
              "idlMemberType"><a>ConstrainDouble</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-principalPointX">principalPointX</a></code> for
              details.
            </dd>
            <dt>
              <dfn><code>principalPointY</code></dfn> of type <span class=
              "idlMemberType"><a>ConstrainDouble</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-principalPointY">principalPointY</a></code> for
              details.
            </dd>
            <dt>
              <dfn><code>deprojectionDistortionCoefficients</code></dfn> of
              type <span class="idlMemberType"><a>ConstrainBoolean</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-deprojectionDistortionCoefficients">deprojectionDistortionCoefficients</a></code>
              for details.
            </dd>
            <dt>
              <dfn><code>projectionDistortionCoefficients</code></dfn> of type
              <span class="idlMemberType"><a>ConstrainBoolean</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-projectionDistortionCoefficients">projectionDistortionCoefficients</a></code>
              for details.
            </dd>
            <dt>
              <dfn><code>depthToVideoTransform</code></dfn> of type
              <span class="idlMemberType"><a>ConstrainBoolean</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-depthToVideoTransform">depthToVideoTransform</a></code>
              for details.
            </dd>
          </dl>
        </section>
      </section>
      <section>
        <h2>
          <code>MediaTrackSettings</code> dictionary
        </h2>
        <pre class="idl">
          partial dictionary MediaTrackSettings {
              DOMString           videoKind;
              double              depthNear;
              double              depthFar;
              double              focalLengthX;
              double              focalLengthY;
              double              principalPointX;
              double              principalPointY;
              DistortionCoefficients deprojectionDistortionCoefficients;
              DistortionCoefficients projectionDistortionCoefficients;
              DepthToVideoTransform depthToVideoTransform;
          };

          dictionary DistortionCoefficients {
              double              k1;
              double              k2;
              double              p1;
              double              p2;
              double              k3;
          };

          dictionary DepthToVideoTransform {
            Float32Array       transformationMatrix;
            DOMString          videoDeviceId;
          };
</pre>
        <section>
          <h2>
            Dictionary <a class="idlType">MediaTrackSettings</a> Members
          </h2>
          <dl data-link-for="MediaTrackSettings" data-dfn-for=
          "MediaTrackSettings" class="dictionary-members">
            <dt>
              <dfn><code>videoKind</code></dfn> of type <span class=
              "idlMemberType"><a>DOMString</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-videoKind">videoKind</a></code> for details.
            </dd>
            <dt>
              <dfn><code>depthNear</code></dfn> of type <span class=
              "idlMemberType"><a>double</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-depthNear">depthNear</a></code> for details.
            </dd>
            <dt>
              <dfn><code>depthFar</code></dfn> of type <span class=
              "idlMemberType"><a>double</a></span>
            </dt>
            <dd>
              See <code><a href="#def-constraint-depthFar">depthFar</a></code>
              for details.
            </dd>
            <dt>
              <dfn><code>focalLengthX</code></dfn> of type <span class=
              "idlMemberType"><a>double</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-focalLengthX">focalLengthX</a></code> for
              details.
            </dd>
            <dt>
              <dfn><code>focalLengthY</code></dfn> of type <span class=
              "idlMemberType"><a>double</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-focalLengthY">focalLengthY</a></code> for
              details.
            </dd>
            <dt>
              <dfn><code>principalPointX</code></dfn> of type <span class=
              "idlMemberType"><a>double</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-principalPointX">principalPointX</a></code> for
              details.
            </dd>
            <dt>
              <dfn><code>principalPointY</code></dfn> of type <span class=
              "idlMemberType"><a>double</a></span>
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-principalPointY">principalPointY</a></code> for
              details.
            </dd>
            <dt>
              The <dfn><code>deprojectionDistortionCoefficients</code></dfn>
              dictionary member represents the <a>depth map</a>'s <a>distortion
              coefficients</a> used when deprojecting from 2D to 3D space.
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-deprojectionDistortionCoefficients">deprojectionDistortionCoefficients</a></code>
              for details.
            </dd>
            <dt>
              The <dfn><code>projectionDistortionCoefficients</code></dfn>
              dictionary member represents the media tracks's <a>distortion
              coefficients</a> used when projecting from 3D to 2D space.
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-projectionDistortionCoefficients">projectionDistortionCoefficients</a></code>
              for details.
            </dd>
            <dt>
              The <dfn><code>depthToVideoTransform</code></dfn> dictionary
              member represents the <a>depth map</a>'s camera's
              <a>transformation from depth to video</a> camera 3D coordinate
              system.
            </dt>
            <dd>
              See <code><a href=
              "#def-constraint-depthToVideoTransform">depthToVideoTransform</a></code>
              for details.
            </dd>
          </dl>
        </section>
        <h3>
          <dfn><code>DistortionCoefficients</code></dfn> dictionary
        </h3>
        <div data-dfn-for="DistortionCoefficients">
          <dl class="dictionary-members">
            <dt>
              The <dfn>k1</dfn>, <dfn>k2</dfn>, <dfn>p1</dfn>, <dfn>p2</dfn>
              and <dfn>k3</dfn> dictionary members represent the
              <a>deprojection distortion coefficients</a> or <a>projection
              distortion coefficients</a>.<br>
              <dfn data-dfn-for="k1">k1</dfn>, <dfn data-dfn-for="k2">k2</dfn>
              and <dfn data-dfn-for="k3">k3</dfn> are <dfn>radial distortion
              coefficients</dfn> while <dfn data-dfn-for="p1">p1</dfn> and
              <dfn data-dfn-for="p2">p2</dfn> are <dfn>tangential distortion
              coefficients</dfn>.<br>
            </dt>
            <dt class="note">
              <a>Radial distortion coefficients</a> and <a>tangential
              distortion coefficients</a> are used when there's need to
              <a>deproject</a> depth value to 3D space or to <a>project</a> 3D
              value to 2D video frame coordinates.<br>
              See <a>algorithm to map depth pixels to color pixels</a> and
              Brown-Conrady distortion model implementation in <a>3D point
              cloud rendering</a> example GLSL shader.<br>
            </dt>
          </dl>
        </div>
        <h3>
          <code>DepthToVideoTransform</code> dictionary
        </h3>
        <div data-dfn-for="DepthToVideoTransform">
          <dl class="dictionary-members">
            <dt>
              The <dfn><code>transformationMatrix</code></dfn> dictionary
              member is a 16 element array that defines the <a>transformation
              matrix</a> of the <a>depth map</a>'s camera's 3D coordinate
              system to video track's camera 3D coordinate system.
            </dt>
            <dt class="note">
              The first four elements of the array correspond to the first
              matrix row, followed by four elements of the second matrix row
              and so on. It is in format suitable for use with WebGL's
              uniformMatrix4fv.
            </dt>
            <dt>
              The <dfn><code>videoDeviceId</code></dfn> dictionary member
              represents the deviceId of video camera the depth stream must be
              synchronized with.
            </dt>
            <dt class="note">
              The value of <a><code>videoDeviceId</code></a> can be used as
              deviceId constraint in [[!GETUSERMEDIA]] to get the corresponding
              video and audio streams.
            </dt>
          </dl>
        </div>
      </section>
      <section>
        <h2>
          Constrainable properties for video
        </h2>
        <p>
          The following constrainable properties are defined to apply only to
          video <a>MediaStreamTrack</a> objects:
        </p>
        <table class="simple">
          <thead>
            <tr>
              <th>
                Property Name
              </th>
              <th>
                Values
              </th>
              <th>
                Notes
              </th>
            </tr>
          </thead>
          <tbody>
            <tr id="def-constraint-videoKind">
              <td>
                <dfn>videoKind</dfn>
              </td>
              <td>
                <code>ConstrainDOMString</code>
              </td>
              <td>
                This string should be one of the members of
                <dfn><code><a>VideoKindEnum</a></code></dfn>. The members
                describe the kind of video that the camera can capture. Note
                that <code>getConstraints</code> may not return exactly the
                same string for strings not in this enum. This preserves the
                possibility of using a future version of WebIDL enum for this
                property.
              </td>
            </tr>
          </tbody>
        </table>
        <div>
          <pre class="idl">
enum VideoKindEnum {
    "color",
    "depth"
};
</pre>
          <table data-link-for="VideoKindEnum" data-dfn-for="VideoKindEnum"
          class="simple">
            <tbody>
              <tr>
                <th colspan="2">
                  Enumeration description
                </th>
              </tr>
              <tr>
                <td>
                  <dfn><code id=
                  "idl-def-VideoKindEnum.color">color</code></dfn>
                </td>
                <td>
                  <p>
                    The source is capturing color images.
                  </p>
                </td>
              </tr>
              <tr>
                <td>
                  <dfn><code id=
                  "idl-def-VideoKindEnum.depth">depth</code></dfn>
                </td>
                <td>
                  <p>
                    The source is capturing depth maps.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </div>
        <div class="note">
          If the user agent requests a combined <a>depth+color stream</a>, the
          devices in the constraint should be satisfied as belonging to the
          same group or physical device. The decision to select and satisfy
          which device pair is left up to the implementation.
        </div>
        <p>
          The <a>MediaStream</a> <a>consumer</a> for the <a>depth-only
          stream</a> and <a>depth+color stream</a> is <a href=
          "#the-video-element">the <code>video</code> element</a> [[!HTML]].
        </p>
        <div class="note">
          New <a>consumer</a>s may be added in a future version of this
          specification.
        </div>
        <p>
          If a <a>MediaStreamTrack</a> whose <code>videoKind</code> of
          <code>Settings</code> is <a>muted</a> or <a>disabled</a>, it MUST
          render frames as if all the pixels would be 0.
        </p>
        <section class="informative">
          <h3>
            Implementation considerations
          </h3>
          <p>
            A <a>color stream track</a> and a <a>depth stream track</a> can be
            combined into one <a>depth+color stream</a>. The rendering of the
            two tracks are intended to be synchronized. The resolution of the
            two tracks are intended to be same. And the coordination of the two
            tracks are intended to be calibrated. These are not hard
            requirements, since it might not be possible to synchronize tracks
            from sources.
          </p>
          <p class="note">
            This approach is simple to use but comes with the following
            caveats: it might might not be supported by the implementation and
            the resolutions of two tracks are intended to be the same that can
            require downsampling and degrade quality. The alternative approach
            is that a web developer implements the <a>algorithm to map depth
            pixels to color pixels</a>. See the <a>3D point cloud rendering</a>
            example code.
          </p>
        </section>
      </section>
      <section>
        <h2>
          Constrainable properties for depth
        </h2>
        <p>
          The following constrainable properties are defined to apply only to
          <a>depth stream track</a>s:
        </p>
        <table class="simple">
          <thead>
            <tr>
              <th>
                Property Name
              </th>
              <th>
                Values
              </th>
              <th>
                Notes
              </th>
            </tr>
          </thead>
          <tbody>
            <tr id="def-constraint-depthNear">
              <td>
                <dfn>depthNear</dfn>
              </td>
              <td>
                <code>ConstrainDouble</code>
              </td>
              <td>
                The <a>near value</a>, in meters.
              </td>
            </tr>
            <tr id="def-constraint-depthFar">
              <td>
                <dfn>depthFar</dfn>
              </td>
              <td>
                <code>ConstrainDouble</code>
              </td>
              <td>
                The <a>far value</a>, in meters.
              </td>
            </tr>
            <tr id="def-constraint-focalLengthX">
              <td>
                <dfn>focalLengthX</dfn>
              </td>
              <td>
                <code>ConstrainDouble</code>
              </td>
              <td>
                The <a>horizontal focal length</a>, in pixels.
              </td>
            </tr>
            <tr id="def-constraint-focalLengthY">
              <td>
                <dfn>focalLengthY</dfn>
              </td>
              <td>
                <code>ConstrainDouble</code>
              </td>
              <td>
                The <a>vertical focal length</a>, in pixels.
              </td>
            </tr>
            <tr id="def-constraint-principalPointX">
              <td>
                <dfn>principalPointX</dfn>
              </td>
              <td>
                <code>ConstrainDouble</code>
              </td>
              <td>
                The <a>principal point x</a> coordinate, in pixels.
              </td>
            </tr>
            <tr id="def-constraint-principalPointY">
              <td>
                <dfn>principalPointY</dfn>
              </td>
              <td>
                <code>ConstrainDouble</code>
              </td>
              <td>
                The <a>principal point y</a> coordinate, in pixels.
              </td>
            </tr>
            <tr id="def-constraint-deprojectionDistortionCoefficients">
              <td>
                <dfn>deprojectionDistortionCoefficients</dfn>
              </td>
              <td>
                <code>ConstrainDOMDictionary</code>
              </td>
              <td>
                The deprojection distortion coefficients.
              </td>
            </tr>
            <tr id="def-constraint-projectionDistortionCoefficients">
              <td>
                <dfn>projectionDistortionCoefficients</dfn>
              </td>
              <td>
                <code>ConstrainDOMDictionary</code>
              </td>
              <td>
                The projection distortion coefficients.
              </td>
            </tr>
            <tr id="def-constraint-depthToVideoTransform">
              <td>
                <dfn>depthToVideoTransform</dfn>
              </td>
              <td>
                <code>ConstrainDOMDictionary</code>
              </td>
              <td>
                The <a>transformation from depth to video</a> camera 3D
                coordinate system.
              </td>
            </tr>
          </tbody>
        </table>
        <p>
          The <code>depthNear</code> and <code>depthFar</code> constrainable
          properties, when set, allow the implementation to pick the best depth
          camera mode optimized for the range <code>[near, far]</code> and help
          minimize the error introduced by the lossy conversion from the depth
          value <var>d</var> to a quantized d<sub>8bit</sub> and back to an
          approximation of the depth value <var>d</var>.
        </p>
        <p>
          If the <code>depthFar</code> property's value is less than the
          <code>depthNear</code> property's value, the <a>depth stream
          track</a> is <a>overconstrained</a>.
        </p>
        <p>
          If the <a>near value</a>, <a>far value</a>, <a>horizontal focal
          length</a> or <a>vertical focal length</a> is fixed due to a hardware
          or software limitation, the corresponding constrainable property's
          value MUST be set to the value reported by the underlying
          implementation. (For example, the focal lengths of the lens may be
          fixed, or the underlying platform may not expose the focal length
          information.)
        </p>
      </section>
      <section>
        <h2>
          <code>WebGLRenderingContext</code> interface
        </h2>
        <section class="informative">
          <h3>
            Implementation considerations
          </h3>
          <div class="note">
            This section is currently work in progress, and subject to change.
          </div>
          <p>
            A <a>video</a> element whose source is a <a>MediaStream</a> object
            containing a <a>depth stream track</a> may be uploaded to a WebGL
            texture of format <code>RGB</code> and type
            <code>UNSIGNED_BYTE</code>. [[WEBGL]]
          </p>
          <p>
            For each pixel of this WebGL texture, the R component represents
            the lower 8 bit value of 16 bit depth value, the G component
            represents the upper 8 bit value of 16 bit depth value and the
            value in B component is not defined.
          </p>
        </section>
      </section>
    </section>
    <section class="informative">
      <h2>
        Synchronizing depth and color video rendering
      </h2>
      <p class="note">
        The algorithms presented in this section explain how a web developer
        can <dfn>map depth and color</dfn> pixels. Concrete example on how to
        do the mapping is provided in example vertex shader used for <a>3D
        point cloud rendering</a>.
      </p>
      <p></p>
      <p>
        When rendering, we want to position a color value from color video
        frame to corresponding <a>depth map value</a> or 3D point in space
        defined by <a>depth map value</a>. We use <a>deprojection distortion
        coefficients</a> to compensate camera distortion when deprojecting 2D
        pixel coordinates to 3D space coordinates and <a>projection distortion
        coefficients</a> in the opposite case, when projecting camera 3D space
        points to pixels.
      </p>
      <p>
        The <dfn>algorithm to map depth pixels to color pixels</dfn> is as
        follows:
      </p>
      <ol>
        <li>
          <a>Deproject</a> <a>depth map value</a> to point in depth 3D space.
        </li>
        <li>
          <a>Transform</a> 3D point from depth camera 3D space to color camera
          3D space.
        </li>
        <li>
          <a>Project</a> from color camera 3D space to color frame 2D pixels.
        </li>
      </ol>
      <p></p>
      <section>
        <h2>
          Deproject to depth 3D space
        </h2>
        <p>
          The algorithm to <dfn>deproject</dfn> depth map value to point in
          depth camera is as follows:
        </p>
        <p>
          Let <var>dx</var> and <var>dy</var> be 2D coordinates, in pixels, of
          a pixel in <a>depth map</a>.
        </p><var></var>
        <p>
          Let <var>dz</var> be <a>depth map value</a> of the same pixel in the
          <a>depth map</a>.
        </p>
        <p>
          Let <var>fx</var> and <var>fy</var> be <a>depth map</a>'s
          <a>horizontal focal length</a> and <a>vertical focal length</a>
          respectively.
        </p>
        <p>
          Let <var>cx</var> and <var>cy</var> be <a>depth map</a>'s
          <a>principal point</a> 2D coordinates.
        </p>
        <p>
          Let 3D coordinates (Xd, Yd, Zd) be the output of this step - a 3D
          point in depth camera's 3D coordinate system.
        </p>
        <p>
          `px = (dx - cx) / (fx)`
        </p>
        <p>
          `py = (dy - cy) / (fy)`
        </p>
        <ul>
          <li>If <a>depth map</a>'s <a>deprojection distortion coefficients</a>
          are <a>not present</a> in <a href=
          "#mediatracksettings-dictionary">MediaTrackSettings</a> dictionary,
            <p>
              3D coordinates (Xd, Yd, Zd) in depth camera space are calculated
              as:
            </p>
            <p>
              `Xd = dz * px`
            </p>
            <p>
              `Yd = dz * px`
            </p>
            <p>
              `Zd = dz`
            </p>
          </li>
          <li>If <a>depth map</a>'s <a>deprojection distortion coefficients</a>
          <a>k1</a>, <a>k2</a>, <a>k3</a>, <a>p1</a> and <a>p2</a> are
          <a>present</a> in <a href=
          "#mediatracksettings-dictionary">MediaTrackSettings</a> dictionary,
          with a note that some of those could be zero,
            <p>
              3D coordinates (Xd, Yd, Zd) in depth camera space are calculated
              as:
            </p>
            <p>
              `r2 = px^2 + py^2`
            </p>
            <p>
              `r = 1 + k1 * r2 + k2 * r2^2 + k3 * r2^3`
            </p>
            <p>
              `Xd = dz * (px * r + 2 * p1 * px * py + p2 * (r2 + 2 * px^2))`
            </p>
            <p>
              `Yd = dz * (py * r + 2 * p2 * px * py + p1 * (r2 + 2 * py^2))`
            </p>
            <p>
              `Zd = dz`
            </p>
          </li>
        </ul>
        <p class="note">
          See depth_deproject function in <a>3D point cloud rendering</a>
          example.
        </p>
      </section>
      <section>
        <h2>
          Transform from depth to color 3D space
        </h2>
        <p>
          The result of <a>project</a> depth value to 3D point step, 3D point
          (Xd, Yd, Zd), is in depth camera 3D coordinate system. To
          <dfn>transform</dfn> coordinates of the same point in space, but to
          color camera 3D coordinate system, we use matrix multiplication of
          <a>transformation from depth to video</a> matrix by the (Xd, Yd, Zd)
          3D point vector.
        </p>
        <p>
          Let (Xc, Yc, Zc) be the output of this step - a 3D coordinates of
          projected <a>depth map value</a> to color camera 3D space.
        </p>
        <p>
          Let <var>M</var> be <a>transformation matrix</a> defined in <a>depth
          map</a>'s <a>depthToVideoTransform</a> field.
        </p>
        <p>
          To multiply 4x4 matrix by 3 element vector, we extend the 3D vector
          by one element to 4 dimensional vector. After multiplication, we use
          vector's x, y and z coordinates as the result.
        </p>
        <p>
          `((Xc), (Yc), (Zc)) = ([M] xx ((Xd), (Yd), (Zd), (1))).xyz`
        </p>
        <p class="note">
          In <a>3D point cloud rendering</a> example, this is done by:
          <code>vec4 color_point = u_depth_to_color * vec4(depth_point,
          1.0);</code>
        </p>
      </section>
      <section>
        <h2>
          Project from color 3D to pixel
        </h2>
        <p>
          To <dfn>project</dfn> from color 3D to 2D coordinate we use the
          corresponding color track's <a href=
          "#mediatracksettings-dictionary">MediaTrackSettings</a>. The color
          track we get using <a>depth map</a>'s <a>depthToVideoTransform</a>
          field <a>videoDeviceId</a> - it represents the target color video
          deviceID that should be used as a constraint with [[!GETUSERMEDIA]]
          call to get the corresponding color video stream track. After that,
          we use color track <a>getSettings()</a> to access <a href=
          "#mediatracksettings-dictionary">MediaTrackSettings</a>.
        </p>
        <p>
          Let `fx_c` and `fy_c` be color track's <a>horizontal focal length</a>
          and <a>vertical focal length</a> respectively.
        </p>
        <p>
          Let `cx_c` and `cy_c` be color track's <a>principal point</a> 2D
          coordinates.
        </p>
        <p>
          The result of this step is 2D coordinate of pixel in color video
          frame (<var>x</var>, <var>y</var>).
        </p>
        <ul>
          <li>If color track's <a>projection distortion coefficients</a>
          <a>k1</a>, <a>k2</a>, <a>k3</a>, <a>p1</a> and <a>p2</a> are
          <a>present</a> in <a href=
          "#mediatracksettings-dictionary">MediaTrackSettings</a> dictionary,
            <p>
              position of pixel in color frame image (x, y) is calculated as:
            </p>
            <p>
              `r2_c = (Xc)^2 + (Yc)^2`
            </p>
            <p>
              `r = 1 + k1 * r2 + k2 * r2^2 + k3 * r2^3`
            </p>
            <p>
              `px_c = r * (Xc) / (Zc)`
            </p>
            <p>
              `py_c = r * (Yc) / (Zc)`
            </p>
            <p>
              `x = (px_c + 2 * p1 * px_c * py_c + p2 * (r2_c + 2 * px_c^2)) *
              fx_c + cx_c`
            </p>
            <p>
              `y = (py_c + 2 * p2 * px_c * py_c + p1 * (r2_c + 2 * py_c^2)) *
              fy_c + cy_c`
            </p>
          </li>
          <li>If color track's <a>projection distortion coefficients</a> are
          <a>not present</a> in <a href=
          "#mediatracksettings-dictionary">MediaTrackSettings</a> dictionary,
            <p>
              position of pixel in color frame image (x, y) is calculated as:
            </p>
            <p>
              `px_c = (Xc) / (Zc)`
            </p>
            <p>
              `py_c = (Yc) / (Zc)`
            </p>
            <p>
              `x = px_c * fx_c + cx_c`
            </p>
            <p>
              `y = py_c * fy_c + cy_c`
            </p>
          </li>
        </ul>
        <p class="note">
          See color_project function in <a>3D point cloud rendering</a>
          example.
        </p>
      </section>
    </section>
    <section class="informative">
      <h2>
        Examples
      </h2>
      <h3>
        Playback of depth and color streams from same device group.
      </h3>
      <pre class="example">
navigator.mediaDevices.getUserMedia({
  video: {videoKind: {exact: "color"}, groupId: {exact: id}}
}).then(function (stream) {
    // Wire the media stream into a &lt;video&gt; element for playback.
    // The RGB video is rendered.
    var video = document.querySelector('#video');
    video.srcObject = stream;
    video.play();
  }
);

navigator.mediaDevices.getUserMedia({
  video: {videoKind: {exact: "depth"}, groupId: {exact: id}}
}).then(function (stream) {
    // Wire the depth-only stream into another &lt;video&gt; element for playback.
    // The depth information is rendered in its grayscale representation.
    var depthVideo = document.querySelector('#depthVideo');
    depthVideo.srcObject = stream;
    depthVideo.play();
  }
);
</pre>
      <h3>
        WebGL Fragment Shader based post-processing
      </h3>
      <pre class="example">
// This code sets up a video element from a depth stream, uploads it to a WebGL
// texture, and samples that texture in the fragment shader, reconstructing the
// 16-bit depth values from the red and green channels.
navigator.mediaDevices.getUserMedia({
  video: {videoKind: {exact: "depth"}}
}).then(function (stream) {
  // wire the stream into a &lt;video&gt; element for playback
  var depthVideo = document.querySelector('#depthVideo');
  depthVideo.srcObject = stream;
  depthVideo.play();
}).catch(function (reason) {
  // handle gUM error here
});

// ... later, in the rendering loop ...
gl.texImage2D(
   gl.TEXTURE_2D,
   0,
   gl.RGB,
   gl.RGB,
   gl.UNSIGNED_BYTE,
   depthVideo
);

&lt;script id="fragment-shader" type="x-shader/x-fragment"&gt;
  varying vec2 v_texCoord;
  // u_tex points to the texture unit containing the depth texture.
  uniform sampler2D u_tex;
  uniform float far;
  uniform float near;
  void main() {
    vec4 floatColor = texture2D(u_tex, v_texCoord);
    float dn = floatColor.r;
    float depth = 0.;
    depth = far * near / ( far - dn * ( far - near));
    // ...
  }
&lt;/script&gt;
</pre>
      <h3>
        WebGL Vertex Shader that implements mapping color and depth
      </h3>
      <p>
        This vertex shader is used for <dfn>3D point cloud rendering</dfn>. The
        code here shows how the web developer can implement <a>algorithm to map
        depth pixels to color pixels</a>. Draw call used is
        glDrawArrays(GL_POINTS, 0, depthMap.width * depthMap.height). Shader
        output is 3D position of vertices (gl_Position) and color texture
        sampling coordinates per vertex.
      </p>
      <pre class="example">
&lt;script id="fragment-shader" type="x-shader/x-fragment"&gt;#version 300 es
#define DISTORTION_NONE 0
#define USE_DEPTH_DEPROJECTION_DISTORTION_COEFFICIENTS 1
#define USE_COLOR_PROJECTION_DISTORTION_COEFFICIENTS 2
uniform mat4 u_mvp;
uniform vec2 u_color_size;
uniform vec2 u_depth_size;
uniform highp usampler2D s_depth_texture;
uniform float u_depth_scale_in_meter;
uniform mat4 u_depth_to_color;
uniform vec2 u_color_offset;
uniform vec2 u_color_focal_length;
uniform float u_color_coeffs[5];
uniform int u_color_projection_distortion;
uniform vec2 u_depth_offset;
uniform vec2 u_depth_focal_length;
uniform float u_depth_coeffs[5];
uniform int u_depth_deprojection_distortion;
out vec2 v_tex;

vec3 depth_deproject(vec2 pixel, float depth)
{
  vec2 point = (pixel - u_depth_offset) / u_depth_focal_length;
  if(u_depth_deprojection_distortion == USE_DEPTH_DEPROJECTION_DISTORTION_COEFFICIENTS)
  {
    float r2 = dot(point, point);
    float f = 1.0 + u_depth_coeffs[0] * r2 + u_depth_coeffs[1] * r2 * r2 + u_depth_coeffs[4] * r2 * r2 * r2;
    float ux = point.x * f + 2.0 * u_depth_coeffs[2] * point.x * point.y +
               u_depth_coeffs[3] * (r2 + 2.0 * point.x * point.x);
    float uy = point.y * f + 2.0 * u_depth_coeffs[3] * point.x * point.y +
               u_depth_coeffs[2] * (r2 + 2.0 * point.y * point.y);
    point = vec2(ux, uy);
  }
  return vec3(point * depth, depth);
}

vec2 color_project(vec3 point)
{
  vec2 pixel = point.xy / point.z;
  if(u_color_projection_distortion == USE_COLOR_PROJECTION_DISTORTION_COEFFICIENTS)
  {
    float r2 = dot(pixel, pixel);
    float f = 1.0 + u_color_coeffs[0] * r2 + u_color_coeffs[1] * r2 * r2 +
              u_color_coeffs[4] * r2 * r2 * r2;
    pixel = pixel * f;
    float dx = pixel.x + 2.0 * u_color_coeffs[2] * pixel.x * pixel.y +
               u_color_coeffs[3] * (r2 + 2.0 * pixel.x * pixel.x);
    float dy = pixel.y + 2.0 * u_color_coeffs[3] * pixel.x * pixel.y +
               u_color_coeffs[2] * (r2 + 2.0 * pixel.y * pixel.y);
    pixel = vec2(dx, dy);
  }
  return pixel * u_color_focal_length + u_color_offset;
}

void main()
{
  vec2 depth_pixel;
  // generate lattice pos; (0, 0) (1, 0) (2, 0) ... (w-1, h-1)
  depth_pixel.x = mod(float(gl_VertexID) + 0.5, u_depth_size.x);
  depth_pixel.y = clamp(floor(float(gl_VertexID) / u_depth_size.x) + 0.5, 0.0, u_depth_size.y);

  // get depth
  vec2 depth_tex_pos = depth_pixel / u_depth_size;
  uint depth = texture(s_depth_texture, depth_tex_pos).r;
  float depth_in_meter = float(depth) * u_depth_scale_in_meter;

  vec3 depth_point = depth_deproject(depth_pixel, depth_in_meter);
  vec4 color_point = u_depth_to_color * vec4(depth_point, 1.0);
  vec2 color_pixel = color_project(color_point.xyz);

  // map [0, w) to [0, 1]
  v_tex = color_pixel / u_color_size;

  gl_Position = u_mvp * vec4(depth_point, 1.0);
}
&lt;/script&gt;
</pre>
    </section>
    <section class="informative">
      <h2>
        Privacy and security considerations
      </h2>
      <p>
        The <a href=
        "https://w3c.github.io/mediacapture-main/#privacy-and-security-considerations">
        privacy and security considerations</a> discussed in [[!GETUSERMEDIA]]
        apply to this extension specification.
      </p>
    </section>
    <section class="appendix">
      <h2>
        Acknowledgements
      </h2>
      <p>
        Thanks to everyone who contributed to the <a href=
        "https://www.w3.org/wiki/Media_Capture_Depth_Stream_Extension">Use
        Cases and Requirements</a>, sent feedback and comments. Special thanks
        to Ningxin Hu for experimental implementations, as well as to the
        Project Tango for their experiments.
      </p>
    </section><!--section id="idl-index" class="appendix"></section-->
  </body>
</html>
